{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XOR_SLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNljVxcQ97QYq1x4JqOYfTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Looma1116/Kaggle-Study_Seungjoon_Lee/blob/main/XOR_SLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9fT3uN3R2g2"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiQvQCeNS9Wj"
      },
      "source": [
        "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]])\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DksZXDGtTNnO",
        "outputId": "e486487a-4612-484b-c298-e3ecae3d664e"
      },
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q16C2lwsTZ8d"
      },
      "source": [
        "SIngle perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ffHdyhTdZ0"
      },
      "source": [
        "#모델정의\n",
        "#Layer 정의\n",
        "linear = torch.nn.Linear(2,1,bias=True) #입력 2개 출력 1개인 선형 노드\n",
        "sigmoid = torch.nn.Sigmoid()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voA2CAKmTqaZ"
      },
      "source": [
        "model = torch.nn.Sequential(linear,sigmoid)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5YV52L8TuEI",
        "outputId": "e57d6583-9470-4444-d579-4c87ad99da57"
      },
      "source": [
        "model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (1): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJWPn5GBTc7m"
      },
      "source": [
        "모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7KSfgSoVFsK"
      },
      "source": [
        "#모델 환경설정\n",
        "#Bianry Cross Entroypy loss\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6VnUbkZVVQj",
        "outputId": "16dbb59c-8891-4f46-b37c-d473fe4cb454"
      },
      "source": [
        "for stop in range(10000):\n",
        "  #그래디언트 초기화\n",
        "  optimizer.zero_grad()\n",
        "  #Forward계산\n",
        "  hypothesis = model(X)\n",
        "  #Error 계산\n",
        "  cost = loss(hypothesis, Y)\n",
        "  #Backward 계산\n",
        "  cost.backward()\n",
        "  #가중치 갱신\n",
        "  optimizer.step()\n",
        "\n",
        "  if stop % 100 == 0:\n",
        "    print(stop, cost.item())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6931471824645996\n",
            "100 0.6931471824645996\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEt7WpNiWESa"
      },
      "source": [
        "모델평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9uZeXApWFaa",
        "outputId": "fb048d46-9370-4846-a24e-f80ae520fce0"
      },
      "source": [
        "#W,b 평가\n",
        "\n",
        "with torch.no_grad() : #임시로 required_grad=false처럼 지금 학슴하는게 아니라고 알려줌\n",
        "  hypothesis = model(X)\n",
        "  predicted = (hypothesis > 0.5).float()\n",
        "  accuracy = (predicted == Y).float().mean()\n",
        "  print('\\n Hypothesis : ', hypothesis.numpy(),'\\n Coreect :', predicted.numpy(),'\\n Accuracy', accuracy.numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Hypothesis :  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            " Coreect : [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            " Accuracy 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DJauayUWsxp"
      },
      "source": [
        "단일 Perceptron 으로는 XOR 문제를 풀 수 없다."
      ]
    }
  ]
}